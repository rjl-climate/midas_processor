# MIDAS Parquet Output Verification

This document describes how to verify and validate the Parquet output generated by the MIDAS processor against the original CSV data.

## Overview

The verification script provides comprehensive validation of the Parquet transformation process, ensuring:

- **Data Integrity**: Row counts, schema correctness, data type validation
- **Content Accuracy**: Sample-based comparison of records between CSV and Parquet
- **Processing Validation**: Verification of deduplication, enrichment, and filtering
- **Quality Assurance**: Preservation of quality flags and metadata
- **Statistical Analysis**: Summary statistics and compression metrics

## Quick Start

### 1. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run Verification

After processing a dataset with the MIDAS processor:

```bash
# Example: Verify uk-daily-temperature-obs dataset
python verify_parquet_output.py \
    --input-csv "/Users/richardlyon/Library/Application Support/midas-fetcher/cache/uk-daily-temperature-obs" \
    --parquet-output "./output/uk-daily-temperature-obs_202501.parquet" \
    --dataset "uk-daily-temperature-obs" \
    --output-dir "./verification_results"
```

### 3. View Results

The script generates two reports:
- **HTML Report**: Human-readable report with visualizations
- **JSON Report**: Machine-readable report for automation

## Verification Tests

### Core Data Integrity Tests

1. **File Existence**: Verifies all required files exist
2. **Schema Validation**: Checks for expected columns and structure
3. **Data Types**: Validates correct data types for each column
4. **Row Count Validation**: Compares record counts (accounting for deduplication)

### Content Validation Tests

5. **Content Integrity**: Sample-based comparison of records
6. **Station Metadata**: Validates station enrichment accuracy
7. **Quality Flags**: Ensures MIDAS quality flags are preserved
8. **Timestamps**: Validates timestamp parsing and ranges
9. **Measurements**: Validates scientific measurement data

### Processing Validation Tests

10. **Processing Flags**: Checks processing operation tracking
11. **Deduplication**: Validates duplicate record handling
12. **Statistical Summary**: Generates compression and processing metrics

## Command Line Options

```bash
python verify_parquet_output.py [OPTIONS]

Required Arguments:
  --input-csv PATH        Path to input CSV directory (MIDAS cache)
  --parquet-output PATH   Path to output Parquet file
  --dataset NAME          Dataset name (e.g., uk-daily-temperature-obs)

Optional Arguments:
  --output-dir PATH       Output directory for reports (default: ./verification_output)
  --sample-size N         Number of CSV files to sample for validation (default: 1000)
  --quiet                 Suppress verbose output

Examples:
  # Basic verification
  python verify_parquet_output.py \
      --input-csv /path/to/csv \
      --parquet-output /path/to/output.parquet \
      --dataset uk-daily-temperature-obs

  # Custom sample size and output location
  python verify_parquet_output.py \
      --input-csv /path/to/csv \
      --parquet-output /path/to/output.parquet \
      --dataset uk-daily-temperature-obs \
      --sample-size 500 \
      --output-dir /custom/output/path
```

## Interpreting Results

### Success Metrics

- **Success Rate**: Percentage of tests that passed
  - â‰¥90%: Excellent data quality
  - 70-89%: Good with minor issues
  - <70%: Significant issues requiring investigation

### Test Results

Each test provides:
- **Status**: PASSED, WARNING, or ERROR
- **Message**: Human-readable description
- **Details**: Additional technical information

### Common Issues and Solutions

#### High Duplicate Count
- **Cause**: Deduplication may not be working correctly
- **Solution**: Check record status priority rules and grouping logic

#### Missing Station Metadata
- **Cause**: Station registry may be incomplete
- **Solution**: Verify station registry loading and matching logic

#### Row Count Mismatch
- **Cause**: Excessive filtering or processing errors
- **Solution**: Check processing pipeline logs and quality control settings

#### Quality Flag Issues
- **Cause**: Quality flags not being preserved
- **Solution**: Verify pass-through implementation in parser

## Automation Integration

### CI/CD Integration

The verification script returns appropriate exit codes:
- `0`: All tests passed (warnings allowed)
- `1`: One or more tests failed

```bash
# In your CI/CD pipeline
python verify_parquet_output.py [args] || exit 1
```

### Programmatic Access

Use the JSON report for programmatic access:

```python
import json

with open('verification_report.json', 'r') as f:
    results = json.load(f)

success_rate = results['success_rate']
failed_tests = results['failed_tests']

if success_rate < 90:
    print(f"Quality alert: Success rate is {success_rate}%")
```

## Advanced Usage

### Custom Validation Rules

Modify the `MIDASVerifier` class to add custom validation logic:

```python
def _validate_custom_business_rule(self, parquet_df):
    # Add your custom validation logic here
    pass
```

### Large Dataset Optimization

For very large datasets:
- Increase `--sample-size` for more thorough validation
- Use `--quiet` mode to reduce output verbosity
- Consider running on a subset of data for quick validation

### Performance Considerations

- **Sample Size**: Higher sample sizes provide better coverage but slower execution
- **Memory Usage**: Large Parquet files are loaded into memory; ensure adequate RAM
- **I/O Performance**: CSV sampling is I/O intensive; SSD storage recommended

## Troubleshooting

### Common Installation Issues

```bash
# If polars installation fails
pip install --upgrade pip
pip install polars --no-cache-dir

# If matplotlib has display issues
export MPLBACKEND=Agg
```

### Memory Issues

For large datasets:
```bash
# Reduce sample size
python verify_parquet_output.py --sample-size 100 [other-args]

# Use streaming processing (modify script if needed)
```

### Path Issues

Ensure paths are absolute or properly quoted:
```bash
python verify_parquet_output.py \
    --input-csv "/full/path/to/csv" \
    --parquet-output "/full/path/to/output.parquet" \
    --dataset "dataset-name"
```

## Report Structure

### HTML Report Sections

1. **Header**: Dataset name, generation time, processing duration
2. **Summary Metrics**: Success rate, test counts, file statistics
3. **Detailed Results**: Individual test results with technical details

### JSON Report Structure

```json
{
  "total_tests": 12,
  "passed_tests": 10,
  "failed_tests": 2,
  "warnings": 1,
  "errors": 1,
  "success_rate": 83.3,
  "dataset_name": "uk-daily-temperature-obs",
  "processing_time": "45.67 seconds",
  "results": [
    {
      "test_name": "schema_validation",
      "passed": true,
      "message": "Schema validation passed",
      "details": {...},
      "severity": "INFO"
    }
  ]
}
```

## Contributing

To add new validation tests:

1. Add a new method to `MIDASVerifier` class following the pattern `_validate_*`
2. Call the method from the `verify()` method
3. Use `_add_result()` to record test outcomes
4. Update this documentation

## Support

For issues or questions:
1. Check the generated HTML report for detailed diagnostics
2. Review the processing logs from the MIDAS processor
3. Verify input data integrity and format compliance